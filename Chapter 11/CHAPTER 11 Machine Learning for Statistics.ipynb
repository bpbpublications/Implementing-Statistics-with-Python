{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset('tips')\n",
    "display(tips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use total_bill as the feature and tip as the target\n",
    "X = tips[['total_bill']]\n",
    "y = tips['tip']\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y, color = 'black')\n",
    "plt.title('Linear Regression Example (Tips Dataset)')\n",
    "plt.xlabel('Total Bill ($)')\n",
    "plt.ylabel('Tip ($)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# train the model on the training set\n",
    "linear_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# calculate the Mean Squared Error (MSE) on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regression line\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_test, y_test, color = 'black')\n",
    "plt.plot(X_test, y_pred, color = 'blue', linewidth = 3)\n",
    "plt.title('Linear Regression Example (Tips Dataset)')\n",
    "plt.xlabel('Total Bill ($)')\n",
    "plt.ylabel('Tip ($)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebec269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# making predictions\n",
    "test_data = pd.DataFrame({'total_bill': [35]})\n",
    "linear_model.predict(X=test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('mpg')\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column indicating if the car is from USA\n",
    "df['is_usa'] = (df['origin'] == 'usa').astype(int)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30570e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select weight as the feature and y as the target\n",
    "X = df[['weight']]\n",
    "y = df['is_usa']\n",
    "\n",
    "# visualize the regression line\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y, color = 'black')\n",
    "plt.title('Scatter plot of weights and is_usa')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('From USA?')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b10228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b636af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26762f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# calculate accuracy and display confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae615a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "mpg = sns.load_dataset(\"mpg\")\n",
    "sns.regplot(x = mpg[\"weight\"], \n",
    "            y = mpg[\"origin\"].eq(\"usa\").rename(\"from_usa\"), \n",
    "            scatter_kws = {\"color\": \"blue\"}, \n",
    "            line_kws = {\"color\": \"red\"},\n",
    "            logistic = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38572e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# making predictions\n",
    "test_data = pd.DataFrame({'weight': [3500, 2200]})\n",
    "print(model.predict(test_data))         # get predictions\n",
    "print(model.predict_proba(test_data))   # get probabilities for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812653c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('prices.csv')\n",
    "sns.lmplot(x = 'floor_area', \n",
    "           y = 'rental_price', \n",
    "           data = df, \n",
    "           hue = 'rented',\n",
    "           palette = 'Set2', \n",
    "           fit_reg = False, \n",
    "           scatter_kws = {\"s\": 50}) # size of circle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0922f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = df[['floor_area','rental_price']].values\n",
    "y = np.where(df['rented']=='y', 1, 0)    #---1 for y and 0 for n---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear').fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27566a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#---min and max for the first feature---\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 \n",
    "\n",
    "#---min and max for the second feature---\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1  \n",
    "\n",
    "#---step size in the mesh---\n",
    "h = (x_max / x_min) / 20 \n",
    "\n",
    "#---make predictions for each of the points in xx,yy---\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), \n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "#---draw the result using a color plot---\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    \n",
    "plt.xlabel('Floor area of house (sq. ft.)')\n",
    "plt.ylabel('Rental price')\n",
    "plt.title(\"Floor area of houses and their rental Prices\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def will_it_rent(floor_area, rental_price):\n",
    "    if(model.predict([[floor_area, rental_price]])) == 0:\n",
    "        print('Will not rent!')\n",
    "    else:\n",
    "        print('Will rent!')\n",
    "\n",
    "#---do some predictions---\n",
    "will_it_rent(1000, 4000)  # Will not rent!\n",
    "will_it_rent(940, 2200)   # Will rent!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# simulate a sample dataset\n",
    "np.random.seed(42)\n",
    "size_of_data = 500\n",
    "\n",
    "data = {\n",
    "    'TotalPurchase': np.random.normal(loc= 1000, \n",
    "                                      scale = 300, \n",
    "                                      size = size_of_data),\n",
    "    'TimeInShop': np.random.normal(loc = 30, \n",
    "                                   scale = 2, \n",
    "                                   size = size_of_data)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# scatter plot for TotalPurchase vs. TimeInShop, colored by cluster labels\n",
    "plt.scatter(df['TotalPurchase'], \n",
    "            df['TimeInShop'], \n",
    "            edgecolor = 'k', \n",
    "            s = 50)\n",
    "plt.xlabel('Total Purchase Amount')\n",
    "plt.ylabel('Time in Shop (minutes)')\n",
    "plt.title('Customers total purchases and time spent in shop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# apply K-Means with k=4 to identify four customer segments\n",
    "kmeans = KMeans(n_clusters = 4, \n",
    "                n_init = 'auto', \n",
    "                random_state = 42)\n",
    "kmeans.fit(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0599ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the cluster labels to the df\n",
    "df['Cluster'] = kmeans.labels_\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# scatter plot for TotalPurchase vs. TimeInShop, colored by cluster labels\n",
    "plt.scatter(df['TotalPurchase'], \n",
    "            df['TimeInShop'], \n",
    "            c = df['Cluster'], \n",
    "            cmap = 'viridis', \n",
    "            edgecolor = 'k', \n",
    "            s = 50)\n",
    "\n",
    "# add labels\n",
    "plt.xlabel('Total Purchase Amount')\n",
    "plt.ylabel('Time in Shop (minutes)')\n",
    "plt.title('Customer Segmentation with K-Means Clustering')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3940ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame([[2000,  26]], \n",
    "                        columns = ['TotalPurchase','TimeInShop'])\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "kmeans.predict(new_data_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935857cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# tokenize sentences into words\n",
    "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
    "\n",
    "# train the Word2Vec model\n",
    "model = Word2Vec(sentences = tokenized_corpus, \n",
    "                 vector_size = 100, \n",
    "                 window = 5, \n",
    "                 min_count = 1, \n",
    "                 workers = 4)\n",
    "\n",
    "# save the model to a file\n",
    "model.save(\"word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the first 10 tokens\n",
    "tokenized_corpus[0][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "loaded_model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "word = 'lousy'\n",
    "# get the vector representation of a word\n",
    "vector_representation = loaded_model.wv[word]\n",
    "print(f\"Vector representation of '{word}':\", vector_representation)\n",
    "\n",
    "# find similar words\n",
    "similar_words = loaded_model.wv.most_similar(word, topn=3)\n",
    "print(f\"Most similar words to '{word}':\", similar_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d308f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = loaded_model.wv.key_to_index\n",
    "print(\"Vocabulary:\", list(vocabulary.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe052d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# original data\n",
    "plt.scatter(X[:, 0], X[:, 1], \n",
    "            c = y,\n",
    "            cmap = 'viridis', \n",
    "            edgecolor = 'k', \n",
    "            s = 50)\n",
    "\n",
    "plt.title('Original Data')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "\n",
    "# plot the legend\n",
    "cmap = plt.get_cmap('viridis')\n",
    "norm = plt.Normalize(y.min(), y.max())\n",
    "handles = [plt.Line2D([0, 0], [0, 0], \n",
    "                      color = cmap(norm(i)), \n",
    "                      marker = 'o', \n",
    "                      linestyle = '', \n",
    "                      label = target)\n",
    "           for i, target in enumerate(iris.target_names)]\n",
    "plt.legend(handles = handles, \n",
    "           title = 'Species')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b10fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# standardize the data with mean = 0 and variance = 1\n",
    "X_standardized = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# apply PCA to reduce the data to 2 dimensions\n",
    "pca = PCA(n_components = 2)\n",
    "X_pca = pca.fit_transform(X_standardized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "            c = y, \n",
    "            cmap = 'viridis', \n",
    "            edgecolor = 'k', \n",
    "            s = 50)\n",
    "plt.title('Reduced Data (2-dimension PCA)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(handles = handles, \n",
    "           title = 'Species')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "_sc = StandardScaler()\n",
    "_pca = PCA(n_components = 2)\n",
    "_model = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('std_scaler', _sc),\n",
    "    ('pca', _pca),\n",
    "    ('regressor', _model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, \n",
    "                     test_size = 0.3,\n",
    "                     shuffle = True, \n",
    "                     random_state = 42)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2053698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.DataFrame([[6.0, 2.9, 4.5, 1.0]])   # sepal length \n",
    "                                                   # sepal width\n",
    "                                                   # petal length\n",
    "                                                   # petal width\n",
    "y_pred = model.predict(test_data)\n",
    "iris.target_names[y_pred[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84f9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
